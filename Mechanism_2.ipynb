{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arminmirrezai/text_privatization/blob/main/Mechanism_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXqQ3mv6SnP3"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3AVcP_6z3mN"
      },
      "source": [
        "## 1.1. Use Colab GPU for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvvG879II6QZ",
        "outputId": "02218c2c-59af-4080-de07-3a43449ae302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8j_AMxjz-Dd"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82wiZUQUz8gC",
        "outputId": "f0698367-6418-42a4-c603-e7ac71599afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# set global seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wNfoLBzxTEW"
      },
      "source": [
        "## 1.2. Install annoy\n",
        "\n",
        "Next we install the annoy library. The annoy library helps us find nearest vectors quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMsZSS1r-iqj",
        "outputId": "fe000fc1-2651-4c49-f393-65932024eb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 102 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 122 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 143 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 646 kB 14.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=394601 sha256=34bbf20da53c8515de598f9f79df5f915a608f742d172f3021bba3e11c8db93e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install annoy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTrXAdJHg3e_"
      },
      "source": [
        "## 1.3. Setting up PySpark in Colab\n",
        "\n",
        "Spark is written in the Scala programming language and requires the Java Virutal Machine (JVM) to run. Therefore, our first task is to download Java. It will help us to do the nearest neighbour computings parallel. For info why PySpark is useful, click [here](https://moviecultists.com/why-we-use-parallelize-in-spark)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVqUPAxOhBYZ"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MSR0CkOhEFJ"
      },
      "source": [
        "Next, we will install Apache Spark 3.0.1 with Hadoop 2.7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6yD8snhhLqW"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYit4BvkhM2z"
      },
      "source": [
        "Now, we just need to unzip that folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFF-ph9nhSlw"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxfIIXf-hV-4"
      },
      "source": [
        "There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2dUFuyzdZu3"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGPgVfRdhgw5"
      },
      "source": [
        "Now that we have install all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run PySpark in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx6c3cEwhqks"
      },
      "outputs": [],
      "source": [
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyKzVFnkhtcD"
      },
      "source": [
        "We need to locate Spark in the system. For that, we import findspark and use findspark.init() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqnAT9ssh0Aj"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w80FFzqe0KmK"
      },
      "source": [
        "## 1.4. Install the Hugging Face Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmShMVsq0R0q"
      },
      "source": [
        "Next, we  install the transformers package from Hugging Face which will give us a pytorch interface for working with BERT. We've selected the pytorch interface because it strikes a nice balance betwee nthe high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT).\n",
        "\n",
        "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to a specific task. For example, in this notebook we will use ``` BertForSequenceClassification```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adUqJ_a60BFQ",
        "outputId": "91e12e7a-c6e7-4911-8ba5-8e69561f8d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 66.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 3.3 kB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f3f6087bb718b5a96b9bc62d9061d997da1e6dbe8c9216a42607646550be3a64\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nMIQZOR8Stb",
        "outputId": "adb10f72-6762-4538-c2d4-5811fd7e9864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9.0) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdxR5Nq1VIc"
      },
      "source": [
        "# 2. Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulREuR0E_Asg"
      },
      "source": [
        "## 2.1. Dutch Book Review Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkRD4NIQ1Z1h"
      },
      "source": [
        "We'll use the [Dutch Book Review Dataset (DBRD)](https://github.com/benjaminvdb/DBRD) to be privatized. It's a set of reviews labeled as positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFLH4Q11Trs",
        "outputId": "4f0204d0-b4f8-4172-b118-42f88a41b9d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijtAbPcDI6Vq"
      },
      "source": [
        "Here we make TabularDataset of our data. This way we can create a vocabulary and add the fine-tuned Dutch fastText model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYYWmkPxBWLj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "# give filepath\n",
        "filepath = 'gdrive/My Drive/Colab Data/MSc thesis/dbrd_preprocessed/complete_data.csv'\n",
        "\n",
        "# prepare sensitive data\n",
        "TEXT = data.Field(sequential=True, include_lengths=True)\n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "fields = [('title', None),\n",
        "          ('sentiment', LABEL),\n",
        "          ('review', TEXT)]\n",
        "\n",
        "# make tabular dataset\n",
        "reviews = data.TabularDataset(\n",
        "    path=filepath, format='csv',\n",
        "    fields=fields,\n",
        "    skip_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WmOx23HBEw1"
      },
      "source": [
        "Next we collect a vocabulary of words that occurs in the dataset. There is a distinction between the phrase count created for word2vec and fastText, because word2vec is only trained on uncased words and fastText has been trained on cased words. \n",
        "\n",
        "The meaning of the word 'Parijs' is sensitive for capitalization in fastText and not in word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq-oNnZZnsfT"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def create_counter(input_data, add_space_split=False, w2v=False):\n",
        "    phrase_count = Counter()\n",
        "    for example in input_data:\n",
        "      review = example.review\n",
        "      original_text = \" \".join(review)\n",
        "      text = original_text.replace(\n",
        "          \" ' \", \"\").replace(\"'\", \"\").replace(\"/\", \" \").replace(\"  \", \" \").replace('\"', '')\n",
        "      if add_space_split:\n",
        "        text = re.split('\\!|\\,|\\n|\\.|\\?|\\-|\\;|\\:|\\(|\\)|\\s', text)\n",
        "      else:\n",
        "        text = re.split('\\!|\\,|\\n|\\.|\\?|\\-|\\;|\\:|\\(|\\)', text)\n",
        "      sentences = [x.strip() for x in text if x.strip()]\n",
        "      if w2v:\n",
        "        for sentence in sentences:\n",
        "          phrase_count[sentence.lower()] += 1\n",
        "      else:\n",
        "        for sentence in sentences:\n",
        "          phrase_count[sentence] += 1\n",
        "    return phrase_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH0u58H4AzvN"
      },
      "source": [
        "Next we create counts and compare the size for word2vec and fastText."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOY5txFAnvea"
      },
      "outputs": [],
      "source": [
        "phrase_count = create_counter(reviews, add_space_split=True)\n",
        "phrase_count_w2v = create_counter(reviews, add_space_split=True, w2v=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQbGGL73BW_b"
      },
      "source": [
        "The size of the vocabulary, when sensitive to capitalization (fastText):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Iu5gFun1q3",
        "outputId": "507b20a6-7921-42c6-9c37-5ecd229d2b0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "144695"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(phrase_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8XcGRnEBddG"
      },
      "source": [
        "The size of the vocabulary, when not sensitive to capitalization (word2vec):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id8DIOpTfmBA",
        "outputId": "ca2a859b-7c32-4270-9875-8acf3a40adbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "129461"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(phrase_count_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK0IDTEclM1_"
      },
      "source": [
        "## 2.2. Embedding Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1zt4POBlM1_"
      },
      "source": [
        "### 2.2.1. word2vec (Option 1)\n",
        "\n",
        "Load the Dutch fine-tuned word2vec embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnPFoDLOlM1_",
        "outputId": "29e9b4a9-6020-495a-877b-3a687d1c4d04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1442950 [00:00<?, ?it/s]Skipping token b'1442950' with 1-dimensional vector [b'320']; likely a header\n",
            "100%|██████████| 1442950/1442950 [02:03<00:00, 11704.72it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "# load embeddings using torchtext\n",
        "# vectors = Vectors('gdrive/My Drive/Colab Data/MSc thesis/word2vec/word2vec_coosto') # file created by gensim\n",
        "vectors_w2v = Vectors('gdrive/My Drive/Colab Data/MSc thesis/word2vec/combined-320.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgJuF9b9lM2A"
      },
      "outputs": [],
      "source": [
        "# compute list of all words in word embedding model\n",
        "words_list_w2v = []\n",
        "for i in range(vectors_w2v.__len__()):\n",
        "  words_list_w2v.append(vectors_w2v.itos[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdMiyFO8lM2A",
        "outputId": "0acfb980-a114-4ced-e8be-1402a6c27fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1442950"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(words_list_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuqdlJN-lM2A"
      },
      "source": [
        "### 2.2.2. fastText (Option 2)\n",
        "\n",
        "Load the Dutch fine-tuned fastText embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ5O0eMNlM2B",
        "outputId": "df35cbc5-20f2-4c02-fb89-de62181ee3dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2000000 [00:00<?, ?it/s]Skipping token b'2000000' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|██████████| 2000000/2000000 [03:13<00:00, 10323.77it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "# attach fastText embeddings\n",
        "vectors_ft = Vectors('gdrive/My Drive/Colab Data/MSc thesis/fastText/cc.nl.300.vec.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkHjQo_mlM2B",
        "outputId": "d78d32f0-7482-4dc9-f183-0a90b2533d88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_list_ft = []\n",
        "for i in range(vectors_ft.__len__()):\n",
        "  words_list_ft.append(vectors_ft.itos[i])\n",
        "len(words_list_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKPI99qqxrFy"
      },
      "source": [
        "### 2.2.3. BERT (Option 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvnGHyhUEZlf"
      },
      "source": [
        "In order to obtain contextual embedding, we have to load the BERTje tokenizer and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "fc9fe9af5d0949acbb76ae369d21b404",
            "16c280b5b7354a5fbd9d2425ae41d9f6",
            "a2ce4c42af70444ebf6c0e2e4257feda",
            "90264679243e404bab7eb8fbc0d67d63",
            "97f375a79baf4f9f80a6411558cd9b58",
            "6ff580376332478faa6304b74df0ab08",
            "a45c3881432b45eebce94ca16f8c2854",
            "321f17880b7844ca885dbbd617f9d430",
            "c4ed8756d9ab43c787aa2ff212b8cf80",
            "2683554dda9544a0a55e07327084d135",
            "e08d006c9cd84b6191e36eed586cf0ab",
            "a808fa57ec3d4b60863b10cfd78c8aef",
            "6dbdc56dc8c84efd9e2d6b5861c2a834",
            "9243538ae44b4e62916d5d0748af138c",
            "7e55a2396d444fa49a6295ac2ed6756a",
            "d0d8c96d53cb41fcacfde67b2108c2d2",
            "adf466d4f0ec4f1fbb83bb49e4a6a974",
            "190459942f4e4aa083fb9c05c374f434",
            "403f3a964add4ca2a1814aaaf1fae2e5",
            "ab4c4483d4d74d4ab427bff9f1a1c870",
            "74a5d3d340944e25a1bc61414c76f883",
            "d464d895596b470faa4ef301f0a697ee",
            "f6320f77247d4fe1aa2bf7351f292e89",
            "e12893a0d62c478cb06237b95c7917d7",
            "886a59900d2f4ed6a0e33d0c98bce0bc",
            "1fddf2989bd24d44b0bd45238df1485f",
            "5d6fb198a3a0452eb24b848f60a53a8b",
            "b0e9ba7e113b4456a0cfb769ec757bee",
            "6dc1640b34894c10a8a2cf3c9b2f36a6",
            "98052c22c61146eeb9141ff828a3eb36",
            "bb7a4227b37442d880eedbdd6ca7f704",
            "47c30750de0c41748117036c5acf30c3",
            "5e07f2856ba540baba4c9562084ceac2",
            "3de4689e950d41f68299c0e27a0d729f",
            "72756bfba29947abb2f33fd3f6dcf430",
            "5792c235deba440cbe7f76f8768264c3",
            "b05ea7d0b0a94563a026372d43efc029",
            "d56c9381512c454b94a5d26fbca0bb8d",
            "653c8080a2ed45ffb29bc2e9b73e4715",
            "314827b54ae94b1d839466e50df55816",
            "9231e0a7a3804ef18e59b216f27687b6",
            "198c8f8611ff4cd08161064d70dc48f7",
            "bd0352df8b0b45c6b3a93d38147f7ab1",
            "77017f53d04c4a4890e818da18b01649"
          ]
        },
        "id": "blG9YhAj3Irz",
        "outputId": "03639781-7d26-4262-9e07-b1bdd31b43d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERTje tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc9fe9af5d0949acbb76ae369d21b404",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/254 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a808fa57ec3d4b60863b10cfd78c8aef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6320f77247d4fe1aa2bf7351f292e89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/236k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3de4689e950d41f68299c0e27a0d729f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERTje tokenizer\n",
        "print('Loading BERTje tokenizer...')\n",
        "BERT_tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a7700351e5364fd8a938b4c61ab31015",
            "2743bd38adc64d5c994f27ba909115ea",
            "8d7d3f90dce841d48b3cce6b532e0861",
            "5a89ebc36e674a4189cb83cc04d541cc",
            "fc18f3cf4f3b49e7a8605f1357f4604a",
            "ad62302f5ca8440484ee00e84b060270",
            "cbddcccef5f44b19b5e41d974bed4e08",
            "d464602ccea94c6490b1cf73641e2290",
            "25cd8318d8b542baaa7da7297f060a43",
            "4f71d2c94bc24739915508c2f46b2b50",
            "ce918862068248ab9cfa8be8ff8f7a90"
          ]
        },
        "id": "GZiBj6-oMwfq",
        "outputId": "511b6750-0283-4729-8c74-980021701f7a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7700351e5364fd8a938b4c61ab31015",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/417M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "# load pre-trained model (weights)\n",
        "BERT_model = AutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\",\n",
        "                                  output_hidden_states = True, # whether the model returns all hidden-states\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HOCrJ0_9O5c"
      },
      "source": [
        "Note that the BERTje model is cased, which means that it is sensitive to capitalization of words. The word 'parijs' does not exist, whereas the word 'Parijs' does. Just as with fastText this is again in contrast with the word2vec model, where everything is lowercase (uncased)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1rA3uYO8nPP",
        "outputId": "fa940773-5877-4ef6-f06f-243c42883bf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30073"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bertje_tokens = []\n",
        "for token in BERT_tokenizer.vocab.keys():\n",
        "  bertje_tokens.append(token)\n",
        "\n",
        "len(bertje_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-RmSVgnlM2E"
      },
      "source": [
        "## 2.3. Build Vocab for Embedding Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCDJTPznlM2E"
      },
      "source": [
        "In order to gain a somewhat fair comparison between the static embedding models, word2vec and fastText, we make a list of words that occur in both the embedding model and the vocabulary. Otherwise a performance advantage could be inherent to fastText as it has 2 million words and word2vec has 1.44 million words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RorEifTyeGMk"
      },
      "outputs": [],
      "source": [
        "vocab_words = list(phrase_count.keys())\n",
        "vocab_words_w2v = list(phrase_count_w2v.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X341XgHBvaa"
      },
      "source": [
        "The number of words that occur in the dataset and are in the word2vec embeddings model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PN8Hkvld0Cm",
        "outputId": "41e30565-df62-461c-827a-c7e18432a4cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94400"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intersect_w2v = list(set(words_list_w2v).intersection(vocab_words_w2v))\n",
        "len(intersect_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh7y5mynB7Q4"
      },
      "source": [
        "The number of words that occur in the dataset and are in the fastText embeddings model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd2CrJ2ieNol",
        "outputId": "4085a378-b684-44ef-81bb-a0efced420c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107708"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intersect_ft = list(set(words_list_ft).intersection(vocab_words))\n",
        "len(intersect_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJx0CUfk8_rv"
      },
      "source": [
        "Now we finally make the vocabularies for the word embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Lab7NblM2G"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "def vocab_counter(words):\n",
        "  \"\"\"\n",
        "  Create a counter that holds all the words that intersect in the word2vec and fasttext vocab.\n",
        "  \"\"\" \n",
        "  vocab_counter = Counter()\n",
        "  for word in words:\n",
        "    vocab_counter[word] += 1\n",
        "  return vocab_counter\n",
        "\n",
        "# create counter for the list of intersecting words\n",
        "w2v_count = vocab_counter(intersect_w2v)\n",
        "\n",
        "# create word2vec vocab\n",
        "w2v_vocab = Vocab(counter=w2v_count)\n",
        "w2v_vocab.load_vectors(vectors_w2v)\n",
        "\n",
        "# create counter for fastText\n",
        "ft_count = vocab_counter(intersect_ft)\n",
        "\n",
        "# create fasttext vocab\n",
        "ft_vocab = Vocab(counter=ft_count)\n",
        "ft_vocab.load_vectors(vectors_ft)\n",
        "\n",
        "# create counter for BERT tokens\n",
        "bert_count = vocab_counter(bertje_tokens)\n",
        "\n",
        "# create BERT vocab\n",
        "BERT_vocab = Vocab(counter=bert_count)\n",
        "BERT_vocab.set_vectors(BERT_tokenizer.vocab, BERT_model.embeddings.word_embeddings.weight.data, dim = 768)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K27KhdpsSpHv"
      },
      "source": [
        "## 2.4. Build Annoy Index (Mechanism 2)\n",
        "\n",
        "We use the annoy library to build an annoy index in order find the nearest vectors quickly. The reason we use Annoy, is because we only need to build the index once, and can pass this index in a parallel computing environment such as PySpark. \n",
        "\n",
        "The main difference with script for Mechanism 1 occurs here. We first randomly project the high dimensional vectors to a smaller dimension. Thereafter, we build an Annoy Index with these smaller vectors. In order randomly project the vectors we first have to determine the dimension we reduce the vectors to (dependent on β) and also define a function that performs the projection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQER2x8qAczy"
      },
      "source": [
        "### 2.4.1. Mechanism 2 Properties\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGKjr3yuAnsH"
      },
      "source": [
        "In the work of [Feyisetan](https://aclanthology.org/2021.trustnlp-1.3/), it is given that in order to keep $(\\epsilon, \\delta)$-privacy our vector with original dimension $d$ has to be reduced to is the following expression: \n",
        "\n",
        "$$\n",
        " m = \\Omega\\left(\\left[\\omega(Ran(M)) + \\sqrt{log(1/\\delta)}\\right]^2 / \\beta^2\\right),\n",
        "$$\n",
        "\n",
        "where $\\Omega$ indicates that it is a dimension, $ω$ is the gaussian width, $Ran(M)$ is the dimension of the embedding model $M$, $\\delta$ is a very small value and $\\beta$ is the dimension reduction parameter.\n",
        "\n",
        "In line with the recommendation of the authors, we set\n",
        "\n",
        "*   $\\omega(Ran(M)) = \\sqrt{log(d)}$,\n",
        "*   $\\delta = 1\\text{e}-6$,\n",
        "*   $\\beta \\in [0.7, 0.8, 0.9]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhcKxSClm5jF"
      },
      "outputs": [],
      "source": [
        "# set beta\n",
        "beta = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PV57aH_AlyT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_new_dim(embedding_dims, beta):\n",
        "  \"\"\"\n",
        "  Calculates new smaller embedding dimension, given a specified embedding dimension and beta.\n",
        "  \"\"\"\n",
        "  return int(np.square(np.log(embedding_dims) + np.sqrt(np.log(1/0.000001))) / np.square(beta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCRF5sOpMYDX"
      },
      "outputs": [],
      "source": [
        "from sklearn import random_projection\n",
        "\n",
        "def reduce_vectors_dim(vocab, new_dim):\n",
        "  \"\"\"\n",
        "  Reduces the dimension of all the original vectors in the vocab object to corresponding new dimension.\n",
        "  \"\"\"\n",
        "  projecter = random_projection.GaussianRandomProjection(n_components=new_dim, random_state=42)\n",
        "  reduced_vectors = torch.tensor(projecter.fit_transform(vocab.vectors))\n",
        "  vocab.vectors = reduced_vectors\n",
        "\n",
        "  return vocab.vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJbFGC6mZP0B"
      },
      "outputs": [],
      "source": [
        "def reduce_single_vector_dim(vector_tensor, new_dim):\n",
        "  \"\"\"\n",
        "  Reduce the dimension of a single vector to corresponding new dimesion.\n",
        "  \"\"\"\n",
        "  projecter = random_projection.GaussianRandomProjection(n_components=new_dim, random_state=42)\n",
        "  vector = vector_tensor.numpy().reshape(1, -1)\n",
        "  reduced_vector = projecter.fit_transform(vector)\n",
        "\n",
        "  return reduced_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_multi_vector_dim(vectors, new_dim):\n",
        "  \"\"\"\n",
        "  Reduce the dimension of multiple vectors to corresponding new dimension.\n",
        "  \"\"\"\n",
        "  projector = random_projection.GaussianRandomProjection(n_components=new_dim, random_state=42)\n",
        "  reduced_vectors = projector.fit_transform(np.array(vectors))\n",
        "\n",
        "  return reduced_vectors"
      ],
      "metadata": {
        "id": "1aRJUmOZPuQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA2-2P7y5aI7"
      },
      "source": [
        "### 2.4.2. Annoy Index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_LqolAMkdVi"
      },
      "source": [
        "We define a function that creates an AnnoyIndex and saves it for later use, for a specified embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B3z1ED1KT7n"
      },
      "outputs": [],
      "source": [
        "from os.path import join\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "def build_AnnoyIndex(emb_vocab, emb_model, embedding_dims, num_trees=50):\n",
        "  \"\"\"\n",
        "  Build AnnoyIndex for a specified embedding model and a vocabulary\n",
        "  \"\"\"\n",
        "  # create approximate nearest neighbor index\n",
        "  ann_index = AnnoyIndex(embedding_dims, 'euclidean')\n",
        "\n",
        "  # initialize annoy index file name\n",
        "  ann_title = 'M2_index_' + emb_model + '.ann'\n",
        "  ann_filename = join('gdrive/My Drive/Colab Data/MSc thesis/Annoy Index/', ann_title)\n",
        "\n",
        "  # add all word vectors in pretrained emb model\n",
        "  for vector_num, vector in enumerate(emb_vocab.vectors):\n",
        "      ann_index.add_item(vector_num, vector)\n",
        "\n",
        "  print(\"Building annoy index...\")\n",
        "  # num_trees affects the build time and the index size\n",
        "  # larger value will give more accurate results, but larger indexes\n",
        "  assert ann_index.build(num_trees)\n",
        "  ann_index.save(ann_filename)\n",
        "  print(\"Annoy index built\")\n",
        "\n",
        "  return ann_filename, ann_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxMJ6Ucbkmtr"
      },
      "source": [
        "#### Annoy Index word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAGJeT6rkq87",
        "outputId": "90027b8e-1fc1-45db-c299-9b4f23fa0467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old dimension:  320\n",
            "New dimension:  183\n",
            "Building annoy index...\n",
            "Annoy index built\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94402"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize model params\n",
        "emb_model = 'word2vec'\n",
        "embedding_dims = 320\n",
        "\n",
        "# calculate new dimension\n",
        "w2v_new_dim = calculate_new_dim(embedding_dims, beta)\n",
        "print(\"Old dimension: \", embedding_dims)\n",
        "print(\"New dimension: \", w2v_new_dim)\n",
        "\n",
        "# reduce the vector dimension\n",
        "reduce_vectors_dim(w2v_vocab, w2v_new_dim)\n",
        "\n",
        "# create annoy index\n",
        "w2v_ann_filename, w2v_ann_index = build_AnnoyIndex(w2v_vocab, emb_model, w2v_new_dim)\n",
        "\n",
        "# print number of vectors in annoy index\n",
        "w2v_ann_index.get_n_items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe919fxr06ao"
      },
      "source": [
        "In the word2vec model the 10 nearest neighbours of the word 'parijs' are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-gTA5bUg1mQ",
        "outputId": "624e68e8-8ea8-4409-ca51-86ef95bee152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parijs\n",
            "straatsburg\n",
            "lyon\n",
            "bordeaux\n",
            "marseille\n",
            "montpellier\n",
            "berlijn\n",
            "antibes\n",
            "frankrijk\n",
            "genève\n"
          ]
        }
      ],
      "source": [
        "word = 'parijs'\n",
        "\n",
        "word_index = w2v_vocab.stoi[word]\n",
        "indices = w2v_ann_index.get_nns_by_item(word_index, 10)\n",
        "\n",
        "for i in indices:\n",
        "  print(w2v_vocab.itos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSEakXcQlgIh"
      },
      "source": [
        "#### Annoy Index fastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6d-ghUgljEh",
        "outputId": "0c0ed51b-c8b2-43dd-9d24-c3a7d9200c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old dimension:  300\n",
            "New dimension:  181\n",
            "Building annoy index...\n",
            "Annoy index built\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "107710"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize model params\n",
        "emb_model = 'fastText'\n",
        "embedding_dims = 300\n",
        "\n",
        "# calculate new dimension\n",
        "ft_new_dim = calculate_new_dim(embedding_dims, beta)\n",
        "print(\"Old dimension: \", embedding_dims)\n",
        "print(\"New dimension: \", ft_new_dim)\n",
        "\n",
        "# reduce the vector dimension\n",
        "reduce_vectors_dim(ft_vocab, ft_new_dim)\n",
        "\n",
        "# create annoy index\n",
        "ft_ann_filename, ft_ann_index = build_AnnoyIndex(ft_vocab, emb_model, ft_new_dim)\n",
        "\n",
        "# print number of vectors in annoy index\n",
        "ft_ann_index.get_n_items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ms6RRWan_gJ"
      },
      "source": [
        "In the fastText model the 10 nearest neighbours of the word 'Parijs' are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMMt80nan_gM",
        "outputId": "8fb1e738-392e-487c-93cf-056d9241a486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parijs\n",
            "Londen\n",
            "Straatsburg\n",
            "Brussel\n",
            "Stockholm\n",
            "Berlijn\n",
            "Milaan\n",
            "Antwerpen\n",
            "Boekarest\n",
            "Bordeaux\n"
          ]
        }
      ],
      "source": [
        "word = 'Parijs'\n",
        "\n",
        "word_index = ft_vocab.stoi[word]\n",
        "indices = ft_ann_index.get_nns_by_item(word_index, 10)\n",
        "\n",
        "for i in indices:\n",
        "  print(ft_vocab.itos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDCYQ3AUUxHY"
      },
      "source": [
        "#### Annoy Index BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4VSzrITytY_",
        "outputId": "e236bb2f-c320-4d3c-ae02-48f8d60905c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old dimension:  768\n",
            "New dimension:  219\n",
            "Building annoy index...\n",
            "Annoy index built\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "30075"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize model params\n",
        "emb_model = 'BERT'\n",
        "embedding_dims = 768\n",
        "\n",
        "# calculate new dimension\n",
        "BERT_new_dim = calculate_new_dim(embedding_dims, beta)\n",
        "print(\"Old dimension: \", embedding_dims)\n",
        "print(\"New dimension: \", BERT_new_dim)\n",
        "\n",
        "# reduce the vector dimension\n",
        "reduce_vectors_dim(BERT_vocab, BERT_new_dim)\n",
        "\n",
        "# create annoy index\n",
        "BERT_ann_filename, BERT_ann_index = build_AnnoyIndex(BERT_vocab, emb_model, BERT_new_dim)\n",
        "\n",
        "# print number of vectors in annoy index\n",
        "BERT_ann_index.get_n_items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC8Fu-T5zKDp",
        "outputId": "06ebcf87-91d4-4a55-cef7-19325af9f446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parijs\n",
            "Londen\n",
            "Franse\n",
            "Amsterdam\n",
            "Brussel\n",
            "Berlijn\n",
            "Nederlandse\n",
            "Italiaanse\n",
            "Gent\n",
            "Duitse\n"
          ]
        }
      ],
      "source": [
        "word = 'Parijs'\n",
        "\n",
        "word_index = BERT_vocab.stoi[word]\n",
        "indices = BERT_ann_index.get_nns_by_item(word_index, 10)\n",
        "\n",
        "for i in indices:\n",
        "  print(BERT_vocab.itos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvtTWEzmVaF_"
      },
      "source": [
        "# 3. Privatization algorithm implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlQAFLZaekAu"
      },
      "source": [
        "The steps of the algorithm are as follows:\n",
        "* For each word in the dataset:\n",
        "  * Obtain word's embedding vector μ.\n",
        "  * Generate a noisy vector $N$. The parameter ```epsilon```  determines the amount of noise added.\n",
        "  * Retrieve the embedding closest to the noisy vector μ + $N$.\n",
        "  * Get the word that correpsonds to the closest vector.\n",
        "  * Replace the original word with the retrieved word closest to the noisy vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQfoy1hqVs5V"
      },
      "source": [
        "## 3.1. Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSLCrzGdqkCb"
      },
      "source": [
        "### 3.1.1. Generate noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOj7IUFTgDXW"
      },
      "source": [
        "In order to generate a noisy vector $N$, we define the following function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei2HZ9BdgKO8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# generate noise vector\n",
        "def generate_laplacian_noise_vector(dimension, sensitivity, epsilon):\n",
        "  \"\"\"\n",
        "  Generates noise to the provided vector dimension and epsilon value.\n",
        "  \"\"\"\n",
        "  # sample normalized random normal vector\n",
        "  rand_vec = np.random.normal(size=dimension)\n",
        "  normalized_vec = rand_vec / np.linalg.norm(rand_vec)\n",
        "\n",
        "  # sample magnituded from gamma distribution\n",
        "  magnitude = np.random.gamma(shape=dimension, scale=sensitivity / epsilon)\n",
        "  \n",
        "  return normalized_vec * magnitude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI2rJZnBWW-n"
      },
      "source": [
        "### 3.1.2. Replace word by nearest to noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OyELwsTWW-v"
      },
      "source": [
        "In order to retrieve the embedding closest to the noisy vector μ + $N$ and retrieving the word corresponding to that embedding, we define the following functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNy0yLigWW-v"
      },
      "source": [
        "#### 3.1.2.1. Static Replace\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuB0tzc5WW-w"
      },
      "outputs": [],
      "source": [
        "def replace_word(sensitive_word, vocab, ann_index, epsilon, embedding_dims, beta):\n",
        "    \"\"\"\n",
        "    Replace a word by injecting noise according to the provided epsilon value \n",
        "    and return a perturbed word.\n",
        "    \"\"\"\n",
        "    # turn word into lowercase for word2vec\n",
        "    if embedding_dims == w2v_new_dim:\n",
        "      sensitive_word = sensitive_word.lower()\n",
        "\n",
        "    # generate a noise vector\n",
        "    sensitivity = 1 + beta\n",
        "    noise = generate_laplacian_noise_vector(embedding_dims, sensitivity, epsilon)\n",
        "\n",
        "    # obtain vector of sensitive word\n",
        "    original_vec = vocab.vectors[vocab.stoi[sensitive_word]]\n",
        "\n",
        "    # obtain perturbed vector\n",
        "    noisy_vector = original_vec + noise\n",
        "\n",
        "    # obtain item closest to noisy vector\n",
        "    closest_item = ann_index.get_nns_by_vector(noisy_vector, 1)[0]\n",
        "\n",
        "    # check if word is out of vocab\n",
        "    # if word is out of vocab return the original word\n",
        "    if vocab.__getitem__(sensitive_word) != 0:\n",
        "      privatized_word = vocab.itos[closest_item]\n",
        "    else:\n",
        "      privatized_word = sensitive_word\n",
        "\n",
        "    return privatized_word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_d-UpvDWW-w"
      },
      "source": [
        "#### word2vec: small example how the word replace mechanism works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7HuYiEFWW-w",
        "outputId": "fbb4ecee-aca8-4a2f-c878-d4f08cc22339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "schotse\n",
            "parijs\n",
            "parijs\n",
            "parijs\n",
            "wekenlang\n",
            "lyon\n",
            "hosson\n",
            "parijs\n",
            "kostschool\n",
            "lucien\n"
          ]
        }
      ],
      "source": [
        "word = 'Parijs'\n",
        "epsilon = 150\n",
        "\n",
        "for i in range(10):\n",
        "  print(replace_word(word, w2v_vocab, w2v_ann_index, epsilon, w2v_new_dim, beta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_sfiDD8U_8E",
        "outputId": "9c5d2a2a-9931-4c8a-d970-e237ee75ccd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Ik ga wel eens op vakantie naar Parijs en soms naar Engeland\n",
            "Privatized:  puzzelstukken welter kia volsta anaesthesie madre jingū tentoonstellingshallen vronski lokaal onderzoekschip voedselvoorraad\n",
            "Privatized:  kuper paginaatjes wel apparaatje onderschriften heuvelts klimt parijs boekverkoopster geschaafd veiligheidsmaatregelen stokes\n",
            "Privatized:  hebt zeg schizofrene asymmetrisch vulnerable quicksilver cuypmarkt lebrun terugneemt schuilplekken kortst melbourne\n",
            "Privatized:  je vranckx nieuwenhuijsen onderschat overkomelijk zoek restverschijnselen valette via panisch krioelt wilkie\n",
            "Privatized:  scratchy cursusleider schaal lichtkegel doodgeërgerd pyramiden onderdoor noopt beweren hoogstens meerzicht recupereren\n",
            "Privatized:  gehuild hagel maatvoeringen flink ilorin conferentie achter parijs geboortegrond losgerukte windsor brighton\n",
            "Privatized:  raaskallen dullens foutief aanwezige modris begeleidster rillanon dagenlange geologiestudent stemgebruik zeiltocht raketkoppen\n",
            "Privatized:  nagelezen cluster nationalistisch tripje voorlaatste vakantie parallel vandervelde rondzwervingen sparrenbos engeland london\n",
            "Privatized:  reisverhaal polyglotbijbel combines geïmpliceerd stripbiografie terugvloog hiernaartoe parijs ging sinusoïde fabrieksmeisjes elizabeths\n",
            "Privatized:  gewichtig ga eens gedaan voorlopig zaterdagmorgen beeldverhaal damascus van contradicties ziek engeland\n"
          ]
        }
      ],
      "source": [
        "sensitive_sent = 'Ik ga wel eens op vakantie naar Parijs en soms naar Engeland'\n",
        "epsilon = 150\n",
        "\n",
        "print(\"Original: \", sensitive_sent)\n",
        "\n",
        "for i in range(10):\n",
        "  privatized_sent = []\n",
        "  for word in sensitive_sent.split():\n",
        "    privatized_sent.append(replace_word(word, w2v_vocab, w2v_ann_index, epsilon, w2v_new_dim, beta))\n",
        "\n",
        "  print(\"Privatized: \", \" \".join(privatized_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jsOkDDWW-y"
      },
      "source": [
        "#### fastText: small example how the word replace mechanism works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sozd2-OWW-y",
        "outputId": "1fe6706c-ab5e-419a-8e8c-4ecc5b3abbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zirkzee\n",
            "Boedapest\n",
            "Rousseau\n",
            "zwaarte\n",
            "Weelen\n",
            "Parijs\n",
            "naderen\n",
            "ignite\n",
            "Rotterdam\n",
            "afgekeurd\n"
          ]
        }
      ],
      "source": [
        "word = 'Parijs'\n",
        "epsilon = 150\n",
        "\n",
        "for i in range(10):\n",
        "  print(replace_word(word, ft_vocab, ft_ann_index, epsilon, ft_new_dim, beta)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnordv3GU7OY",
        "outputId": "7bfa7a7a-8d37-47b1-9620-43c2f8ef7392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Ik ga wel eens op vakantie naar Parijs en soms naar Engeland\n",
            "Privatized:  Ik ga wel nooit op portugues naar Wenen en Soms daarmede Missis\n",
            "Privatized:  Ik ga wel ding op Ardennen naar Carlan en maak zicht Columbia\n",
            "Privatized:  Ik ga wel eens op Dieulafoy graag Carnaval en net vanuit Hoboken\n",
            "Privatized:  Ik ga wel even op Hauger naar Lille en soms Tsjechië oktober\n",
            "Privatized:  Ik ga wel ergens op luchtrace naar Carriere en dagen heden Palmers\n",
            "Privatized:  Ik ga wel maatje op Huysentruyt Schuyler 1981 en haast terug tienerfilm\n",
            "Privatized:  Ik ga wel eens op vijftigste naar Parijs en soms mijn morning\n",
            "Privatized:  Ik ga wel effe op Lohmark naar Billancourt en soms naar ballingsoord\n",
            "Privatized:  Ik ga niet eens op vakantietrip langs Bonnart en boedel naar uitgestuurd\n",
            "Privatized:  Ik ga wel eens op Toestanden naar Parijs en soms meeneem Fouquet\n"
          ]
        }
      ],
      "source": [
        "sensitive_sent = 'Ik ga wel eens op vakantie naar Parijs en soms naar Engeland'\n",
        "epsilon = 150\n",
        "\n",
        "print(\"Original: \", sensitive_sent)\n",
        "\n",
        "for i in range(10):\n",
        "  privatized_sent = []\n",
        "  for word in sensitive_sent.split():\n",
        "    privatized_sent.append(replace_word(word, ft_vocab, ft_ann_index, epsilon, ft_new_dim, beta))\n",
        "\n",
        "  print(\"Privatized: \", \" \".join(privatized_sent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B8Ch3nWPhOu"
      },
      "source": [
        "#### BERT: small example how the word replace mechanism works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwZC4vYfPAc-",
        "outputId": "20cd31e2-c8b4-4d02-bbe8-3c0d269d90e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rachel\n",
            "dr\n",
            "Unilever\n",
            "##o\n",
            "German\n",
            "Zwolle\n",
            "vlinder\n",
            "Parijs\n",
            "was\n",
            "huis\n"
          ]
        }
      ],
      "source": [
        "word = 'Parijs'\n",
        "epsilon = 150\n",
        "\n",
        "for i in range(10):\n",
        "  print(replace_word(word, BERT_vocab, BERT_ann_index, epsilon, BERT_new_dim, beta)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xFRVcgCPnwW",
        "outputId": "b0c31962-4e7e-4349-8202-ed1b96f4c5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Ik ga wel eens op vakantie naar Parijs en soms naar Engeland\n",
            "Privatized:  ##H ga wel in op vakantie ##heden meldde tijd soms In Engeland\n",
            "Privatized:  ik Bovendien weer Leiden op vakantie naar gaat en verdwijnen naar Europa\n",
            "Privatized:  Ik ##er wel af op toeristen 43 Wenen en even EK Duitsland\n",
            "Privatized:  We ga wel groot op reis zogenaamd Brabant en gedenkteken naar religie\n",
            "Privatized:  uitgevoerd stoot wel eens van vaak naar Julia en soms wekt België\n",
            "Privatized:  ##centra organisator wel nieuws op vrijheid naar 16 en bedrijven opgenomen Howard\n",
            "Privatized:  ik ga wel plaatsen tot lunch uit Parijs en ##blijft stapje Duitsland\n",
            "Privatized:  Ik FNV wel eens op internet naar Parijs en soms naar achtste\n",
            "Privatized:  1986 <unk> wel eens op interview naar Parijs en eigenlijk naar Oslo\n",
            "Privatized:  ik juli wel eens op vakantie Europa ##mar en soms naar Engeland\n"
          ]
        }
      ],
      "source": [
        "sensitive_sent = 'Ik ga wel eens op vakantie naar Parijs en soms naar Engeland'\n",
        "epsilon = 150\n",
        "\n",
        "print(\"Original: \", sensitive_sent)\n",
        "\n",
        "for i in range(10):\n",
        "  privatized_sent = []\n",
        "  for word in sensitive_sent.split():\n",
        "    privatized_sent.append(replace_word(word, BERT_vocab, BERT_ann_index, epsilon, BERT_new_dim, beta))\n",
        "\n",
        "  print(\"Privatized: \", \" \".join(privatized_sent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFMPGorEyIZ6"
      },
      "source": [
        "#### 3.1.2.2. Contextual Replace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoNmLo5D5rBk"
      },
      "source": [
        "Here we have to put the input text into a specific format that BERT can read. Mainly we add the ```[CLS]``` to the beginning and ```[SEP]``` to the end of the input. Then we convert the tokenized BERT input to the tensor format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5GKOZx7Xo4M"
      },
      "outputs": [],
      "source": [
        "def bert_text_preparation(text, tokenizer):\n",
        "  \"\"\"\n",
        "  Preprocesses text input in a way that BERT can interpret.\n",
        "  \"\"\"\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "  tokenized_text = tokenizer.tokenize(marked_text, truncation=True)\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  segments_ids = [1]*len(indexed_tokens)\n",
        "\n",
        "  # convert inputs to tensors\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensor = torch.tensor([segments_ids])\n",
        "\n",
        "  return tokenized_text, tokens_tensor, segments_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXd1Lws5wAp"
      },
      "source": [
        "Now we can compute the BERT token embedding. Here we will use the first layer of the BERT model as the contextual model. We found chose this layer by trial and error. According to the authors of BERT, it is highly task specific which layer(s) of combination of layers works best.\n",
        "\n",
        "In our case, we would like the contextual embeddings to look somewhat like the non-contextual embeddings, because we have built an Annoy Index based on the non-contextual embeddings. If the embeddings keep a similar 'shape/direction', the performance is best. We hypothesise that this is due to the fact that if you take a 'very contextual' embedding, for instance the last layer, it won't be near the non-contextual embedding in our Annoy Index. This will cause our mechanism not to find suitable nearest neighbours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqYxJi28X63W"
      },
      "outputs": [],
      "source": [
        "def get_bert_embeddings(tokens_tensor, segments_tensor, model):\n",
        "    \"\"\"\n",
        "    Obtains BERT embeddings for tokens, in context of the given sentence.\n",
        "    \"\"\"\n",
        "    # gradient calculation id disabled\n",
        "    with torch.no_grad():\n",
        "      # obtain hidden states\n",
        "      outputs = model(tokens_tensor, segments_tensor)\n",
        "      hidden_states = outputs[2]\n",
        "\n",
        "    # concatenate the tensors for all layers\n",
        "    # use \"stack\" to create new dimension in tensor\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "    # remove dimension 1, the \"batches\"\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "    # swap dimensions 0 and 1 so we can loop over tokens\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # intialized list to store embeddings\n",
        "    token_vecs_first = []\n",
        "\n",
        "    # \"token_embeddings\" is a [Y x 12 x 768] tensor\n",
        "    # where Y is the number of tokens in the sentence\n",
        "\n",
        "    # loop over tokens in sentence\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        # \"token\" is a [12 x 768] tensor\n",
        "\n",
        "        # Sum the vectors from the last four layers.\n",
        "        # sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "        # take first layer\n",
        "        first_vec = token[0]\n",
        "        token_vecs_first.append(first_vec.numpy())\n",
        "\n",
        "    return token_vecs_first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZARGpOlGBh--"
      },
      "source": [
        "In order to privatize the contextual token embeddings we first need to create a Annoy Index filled with contextual embeddings. For this we will create contextual embeddings for a sample of the dataset, otherwise we will have to many embeddings (note that this is because in the contexual perspective words like 'de' and 'een' have different embeddings each time).\n",
        "\n",
        "The sample of the dataset will be a 10 percent split of the original dataset. We will make a list of tuples, where each tuple is the string and its corresponding embeddings. For this list of tuples we make a Annoy Index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvQFQIqmDXY1"
      },
      "source": [
        "First we create the 10 percent split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIJ6aQyz6mX6",
        "outputId": "695eb1ae-5a6c-4c3b-ca5b-6a662be93e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 22,226\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get filepath\n",
        "filepath = 'gdrive/My Drive/Colab Data/MSc thesis/dbrd_preprocessed/complete_data.csv'\n",
        "\n",
        "# get dataframe\n",
        "df = pd.read_csv(filepath, index_col = 0)\n",
        "df = df.dropna()\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of sentences: {:,}\\n'.format(df.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6gxIyB--EJc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lNzkQT-D79H",
        "outputId": "395676c4-a6bc-4f00-c370-3268f14c93c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 1,112\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = df_test.sentence.values\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of sentences: {:,}\\n'.format(df_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1hhi3_6EFWl"
      },
      "source": [
        "Then we create a contextual embeddings for each word in each sentence in our sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h43jeTEEkHo"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "context_emb = []\n",
        "context_emb_tokens = []\n",
        "\n",
        "for sentence in sentences:\n",
        "  # obtain contextual BERT embeddings\n",
        "  tokenized_text, tokens_tensor, segments_tensor = bert_text_preparation(sentence, BERT_tokenizer)\n",
        "  list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensor, BERT_model)\n",
        "\n",
        "  # reduce dimension of all token embeddings\n",
        "  list_red_token_embeddings = reduce_multi_vector_dim(list_token_embeddings, BERT_new_dim)\n",
        "    \n",
        "  # make ordered dictionary to keep track of the position of each word\n",
        "  tokens = OrderedDict()\n",
        "\n",
        "  # loop over tokens in sensitive sentence\n",
        "  for token in tokenized_text[1:-1]:\n",
        "    # keep track of position of word and whether it occurs multiple times\n",
        "    if token in tokens:\n",
        "      tokens[token] += 1\n",
        "    else:\n",
        "      tokens[token] = 1\n",
        "\n",
        "    # compute the position of the current token\n",
        "    token_indices = [i for i, t in enumerate(tokenized_text) if t == token]\n",
        "    current_index = token_indices[tokens[token]-1]\n",
        "\n",
        "    # get the corresponding embedding\n",
        "    token_vec = list_red_token_embeddings[current_index]\n",
        "\n",
        "    # reduced dimension of embedding\n",
        "    # new_token_vec = reduce_single_vector_dim(token_vec, BERT_new_dim)[0]\n",
        "\n",
        "    context_emb.append((token, token_vec))\n",
        "    context_emb_tokens.append(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv3HgyKaIuh_"
      },
      "source": [
        "Now we make the Annoy Index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crSi3TpTI-Rd"
      },
      "outputs": [],
      "source": [
        "from os.path import join\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "def build_AnnoyIndex_context(contex_emb, emb_model, embedding_dims, num_trees=50):\n",
        "  \"\"\"\n",
        "  Build AnnoyIndex for a specified embedding model and a vocabulary\n",
        "  \"\"\"\n",
        "  # create approximate nearest neighbor index\n",
        "  ann_index = AnnoyIndex(embedding_dims, 'euclidean')\n",
        "\n",
        "  # initialize annoy index file name\n",
        "  ann_title = 'M2_index_' + emb_model + '.ann'\n",
        "  ann_filename = join('gdrive/My Drive/Colab Data/MSc thesis/Annoy Index/', ann_title)\n",
        "\n",
        "  # add all word vectors in list of contextual embeddings\n",
        "  for vector_num, vector in enumerate(context_emb):\n",
        "      ann_index.add_item(vector_num, vector[1])\n",
        "\n",
        "  print(\"Building annoy index...\")\n",
        "  # num_trees affects the build time and the index size\n",
        "  # larger value will give more accurate results, but larger indexes\n",
        "  assert ann_index.build(num_trees)\n",
        "  ann_index.save(ann_filename)\n",
        "  print(\"Annoy index built\")\n",
        "\n",
        "  return ann_filename, ann_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvahjca1IOQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc978b16-84cb-4606-b82d-74f7db98d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building annoy index...\n",
            "Annoy index built\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289533"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# initialize model params\n",
        "emb_model = 'BERT_context'\n",
        "\n",
        "# create annoy index\n",
        "BERT_context_ann_filename, BERT_context_ann_index = build_AnnoyIndex_context(context_emb, emb_model, BERT_new_dim)\n",
        "\n",
        "# print number of vectors in annoy index\n",
        "BERT_context_ann_index.get_n_items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDMrPO7GRHUl"
      },
      "source": [
        "Now remove the ```context_emb``` variable, as it was only needed for the annoy index and is taking up much RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-nRuhV8RuBP"
      },
      "outputs": [],
      "source": [
        "del context_emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUi1QZ1ISacI"
      },
      "source": [
        "The following function privatizes a contextual token embedding. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hLd_hECSacK"
      },
      "outputs": [],
      "source": [
        "def replace_word_context(sensitive_vec, context_emb_tokens, ann_index, epsilon, embedding_dims, beta):\n",
        "    \"\"\"\n",
        "    Replace a word by injecting noise according to the provided epsilon value \n",
        "    and return a perturbed word.\n",
        "    \"\"\"\n",
        "    # generate a noise vector\n",
        "    sensitivity = 1 + beta\n",
        "    noise = generate_laplacian_noise_vector(embedding_dims, sensitivity, epsilon)\n",
        "\n",
        "    # obtain perturbed vector\n",
        "    noisy_vector = sensitive_vec + noise\n",
        "\n",
        "    # obtain item closest to noisy vector\n",
        "    closest_item = ann_index.get_nns_by_vector(noisy_vector, 1)[0]\n",
        "\n",
        "    # get word from item\n",
        "    privatized_word = context_emb_tokens[closest_item]\n",
        "    \n",
        "    return privatized_word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daLb9G-CRYyi"
      },
      "source": [
        "Small example how the word replace mechanism works for the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn51djp8RYyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b637bdb3-5e56-4968-e52d-d3cd6949a6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  Ik ga wel eens op vakantie naar Parijs en soms naar Engeland\n",
            "Privatized sentence:  Ik ga wel eens op vakantie naar universiteit en soms naar Engeland\n",
            "Privatized sentence:  Ik ga wel ##s op vakantie naar Naar en soms naar Londen\n",
            "Privatized sentence:  Ik ga wel eens op meemaken naar vage en soms naar Frankrijk\n",
            "Privatized sentence:  Ik regelen wel eens op ##ga naar Londen en soms naar Gi\n",
            "Privatized sentence:  Ik ging wel eens op vakantie naar Parijs en soms naar Engeland\n",
            "Privatized sentence:  Ik ga wel eens op vakantie naar mooie en soms naar Engeland\n",
            "Privatized sentence:  Ik ga wel eens op familie naar Edwards en soms naar En\n",
            "Privatized sentence:  Ik maand wel eens op vakantie naar Rotterdam en soms naar omdat\n",
            "Privatized sentence:  Ik ga wel eens op vakantie naar Parijs en soms naar Italië\n",
            "Privatized sentence:  Ik ga wel eens op vakantie Miss Spaanse en soms naar Engeland\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# settings\n",
        "sensitive_sent = 'Ik ga wel eens op vakantie naar Parijs en soms naar Engeland'\n",
        "epsilon = 15\n",
        "\n",
        "print(\"Original sentence: \", sensitive_sent)\n",
        "\n",
        "# obtain contextual BERT embeddings\n",
        "tokenized_text, tokens_tensor, segments_tensor = bert_text_preparation(sensitive_sent, BERT_tokenizer)\n",
        "list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensor, BERT_model)\n",
        "\n",
        "# reduce dimension of all token embeddings\n",
        "list_red_token_embeddings = reduce_multi_vector_dim(list_token_embeddings, BERT_new_dim)\n",
        "\n",
        "for j in range(10):\n",
        "  \n",
        "  # make ordered dictionary to keep track of the position of each word\n",
        "  sensitive_tokens = OrderedDict()\n",
        "\n",
        "  # initialize privatized sentence\n",
        "  private_sent = []\n",
        "\n",
        "  # loop over tokens in sensitive sentence\n",
        "  for sensitive_token in tokenized_text[1:-1]:\n",
        "    # keep track of position of word and whether it occurs multiple times\n",
        "    if sensitive_token in sensitive_tokens:\n",
        "      sensitive_tokens[sensitive_token] += 1\n",
        "    else:\n",
        "      sensitive_tokens[sensitive_token] = 1\n",
        "\n",
        "    # compute the position of the current token\n",
        "    token_indices = [i for i, token in enumerate(tokenized_text) if token == sensitive_token]\n",
        "    current_index = token_indices[sensitive_tokens[sensitive_token]-1]\n",
        "\n",
        "    # get the corresponding embedding\n",
        "    sensitive_vec = list_red_token_embeddings[current_index]\n",
        "\n",
        "    # privatize word\n",
        "    privatized_word = replace_word_context(sensitive_vec, context_emb_tokens, BERT_context_ann_index, epsilon, BERT_new_dim, beta)\n",
        "    private_sent.append(privatized_word)\n",
        "\n",
        "  print(\"Privatized sentence: \", \" \".join(private_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTjwBh8WrSvT"
      },
      "source": [
        "### 3.1.3. Privatize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_MrKiBqiCda"
      },
      "source": [
        "In order to replace the original words in a sensitive review with a privatized review, we define the following functions for the static case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-HMGPrMnuB1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def obtain_phrases(example):\n",
        "  \"\"\"\n",
        "  Remove special characters in the review and chop review in to smaller phrases.\n",
        "  \"\"\"\n",
        "  original_text = \" \".join(example.review)\n",
        "  clean_text = original_text.replace(\n",
        "      \"'\", \" \").replace(\"/\", \" \").replace(\"  \", \" \").replace('\"', '')\n",
        "  text = re.split('\\!|\\,|\\n|\\.|\\?|\\-|\\;|\\:|\\(|\\)', clean_text)\n",
        "  \n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnEoSxWfwswy"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "import itertools\n",
        "\n",
        "def privatize_example_static(example, emb_model, local_vocab, local_epsilon, local_embedding_dims, local_beta):\n",
        "  \"\"\"\n",
        "  Replace a word by injecting noise according to the provided epsilon value \n",
        "  and return a perturbed word.\n",
        "  \"\"\"\n",
        "  from annoy import AnnoyIndex\n",
        "  # load the annoy index to find nearest neighbours\n",
        "  local_index = AnnoyIndex(local_embedding_dims, 'euclidean') \n",
        "  if \"word2vec\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_word2vec.ann\"))\n",
        "  elif \"fastText\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_fastText.ann\"))\n",
        "  elif \"BERT\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_BERT.ann\"))\n",
        "\n",
        "  # make remove any space at the end of the cleaned phrases\n",
        "  sensitive_phrases = [phrase.strip() for phrase in obtain_phrases(example) if phrase.strip()]\n",
        "\n",
        "  # make list privatized phrases\n",
        "  privatized_phrases = []\n",
        "  for sensitive_phrase in sensitive_phrases:\n",
        "    privatized_words = []\n",
        "    for sensitive_word in sensitive_phrase.split(' '):\n",
        "      privatized_word = replace_word(sensitive_word, local_vocab, local_index, local_epsilon, local_embedding_dims, local_beta)\n",
        "      if privatized_word == '\"' or privatized_word == \"'\" or privatized_word ==\",\":\n",
        "        continue\n",
        "      else: \n",
        "        privatized_words.append(privatized_word)\n",
        "\n",
        "    # flatten nested list of words\n",
        "    privatized_phrases.append(itertools.chain(*[privatized_words]))\n",
        "\n",
        "  # reconstruct review\n",
        "  privatized_review = \" \".join(list(itertools.chain(*privatized_phrases)))\n",
        "\n",
        "  # reconstruct row\n",
        "  privatized_row = \"\\\"{}\\\",{}\".format(privatized_review, example.sentiment)\n",
        "\n",
        "  return privatized_row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZENjr0UGtCz"
      },
      "source": [
        "For the contextual case, we use a slightly different function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT1_ro5iJNt8"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "import itertools\n",
        "\n",
        "def privatize_example_context(example, emb_model, context_emb_tokens, local_epsilon, local_embedding_dims, local_beta, model, tokenizer):\n",
        "  \"\"\"\n",
        "  Replace a word by injecting noise according to the provided epsilon value \n",
        "  and return a perturbed word.\n",
        "  \"\"\"\n",
        "  from annoy import AnnoyIndex\n",
        "  # load the annoy index to find nearest neighbours\n",
        "  local_index = AnnoyIndex(local_embedding_dims, 'euclidean') \n",
        "  if \"BERT_context\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_BERT_context.ann\"))\n",
        "\n",
        "  # make ordered dictionary to keep track of the position of each word\n",
        "  sensitive_tokens = OrderedDict()\n",
        "\n",
        "  # initialize private sentence\n",
        "  privatized_sent = []\n",
        "\n",
        "  # initialize review\n",
        "  review = \" \".join(example.review)\n",
        "\n",
        "  # obtain contexual BERT embeddings\n",
        "  tokenized_text, tokens_tensor, segments_tensor = bert_text_preparation(review, tokenizer)\n",
        "  list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensor, model)\n",
        "\n",
        "  # reduce dimension of all token embeddings\n",
        "  list_red_token_embeddings = reduce_multi_vector_dim(list_token_embeddings, BERT_new_dim)\n",
        "\n",
        "  # loop over tokens in sensitive sentence\n",
        "  for sensitive_token in tokenized_text[1:-1]:\n",
        "    # keep track of position of word and whether it occurs multiple times\n",
        "    if sensitive_token in sensitive_tokens:\n",
        "      sensitive_tokens[sensitive_token] += 1\n",
        "    else:\n",
        "      sensitive_tokens[sensitive_token] = 1\n",
        "\n",
        "    # compute the position of the current token\n",
        "    token_indices = [i for i, token in enumerate(tokenized_text) if token == sensitive_token]\n",
        "    current_index = token_indices[sensitive_tokens[sensitive_token]-1]\n",
        "\n",
        "    # get the corresponding embedding\n",
        "    sensitive_vec = list_red_token_embeddings[current_index]\n",
        "\n",
        "    # privatize word\n",
        "    privatized_word = replace_word_context(sensitive_vec, context_emb_tokens, local_index, local_epsilon, local_embedding_dims, local_beta)\n",
        "\n",
        "    if privatized_word == '\"' or privatized_word == \"'\":\n",
        "      continue\n",
        "    else: \n",
        "      privatized_sent.append(privatized_word)\n",
        "\n",
        "  # reconstruct review\n",
        "  privatized_review = \" \".join(privatized_sent)\n",
        "\n",
        "  # reconstruct row\n",
        "  privatized_row = \"\\\"{}\\\",{}\".format(privatized_review, example.sentiment)\n",
        "\n",
        "  return privatized_row\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8DMOle5G6IP"
      },
      "source": [
        "### 3.1.4. Miscellaneous utility functions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV-52JBmC6zC"
      },
      "source": [
        "A function that renames the various output files so they have an extension \".txt\". PySpark does not do this automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx07hIsbDBk_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# rename files to append '.txt' to filename\n",
        "def rename_files(file_directory):\n",
        "  \"\"\"\n",
        "  PySpark files are saved without an extension, therefore we rename the file to add the .txt extension.\n",
        "  Also compile the files into one dataframe.\n",
        "  \"\"\"\n",
        "  # rename files to add .txt extension\n",
        "  for f in os.listdir(file_directory):\n",
        "    path = os.path.join(file_directory, f)\n",
        "    if not os.path.isfile(path):\n",
        "      continue  # A directory or some other weird object\n",
        "    if not os.path.splitext(f)[1]:\n",
        "      os.rename(path, path + '.txt')\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvG4n0IeHNM7"
      },
      "source": [
        "A function that visualizes distances results for our privacy experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYJeCEB3E_80"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_cmap(n, name='hsv'):\n",
        "  '''\n",
        "  Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
        "  RGB color; the keyword argument name must be a standard mpl colormap name.\n",
        "  '''\n",
        "  return plt.cm.get_cmap(name, n)\n",
        "\n",
        "def plot_pertubations(dist, epsilons, title):\n",
        "  \"\"\"\n",
        "  Function that plots the avg distance between each word and it perturbations given specified epsilons.\n",
        "  \"\"\"\n",
        "  cmap = get_cmap(len(dist))\n",
        "\n",
        "  # specifying the plot size\n",
        "  plt.figure(figsize = (10, 5))\n",
        "  \n",
        "  # only one line may be specified; full height\n",
        "  i = 0\n",
        "  for value in dist: \n",
        "    plt.axvline(x = value, color = cmap(i), label = 'epsilon: ' + str(epsilons[i]))\n",
        "    i += 1\n",
        "\n",
        "  # place legend outside\n",
        "  plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper left')\n",
        "\n",
        "  # set labels\n",
        "  plt.xlabel('Euclidean distance')\n",
        "  plt.title(title)\n",
        "  plt.grid()\n",
        "  \n",
        "  # rendering plot\n",
        "  plt.show()\n",
        "\n",
        "  return None\n",
        "\n",
        "def plot_nn(dist, k_list, title):\n",
        "  \"\"\"\n",
        "  Function that plots that avg distance between each words and its k nearest neigbours.\n",
        "  \"\"\"\n",
        "  # create function to make colour in figure\n",
        "  cmap = get_cmap(len(dist))\n",
        "\n",
        "  # specifying the plot size\n",
        "  plt.figure(figsize = (10, 10))\n",
        "  \n",
        "  # only one line may be specified; full height\n",
        "  for i in range(len(dist)): \n",
        "    plt.plot(dist[i], k_list[i], 'ro', color = cmap(i), label = 'k: ' + str(k_list[i]))\n",
        "\n",
        "  # plt.scatter(avg_distances, k_list)\n",
        "  # place legend outside\n",
        "  plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper left')\n",
        "\n",
        "  # set labels\n",
        "  plt.xlabel('Euclidean distance')\n",
        "  plt.ylabel('k nearest neighbours')\n",
        "  plt.title(title)\n",
        "  plt.grid()\n",
        "  \n",
        "  # rendering plot\n",
        "  plt.show()\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jos6qnlkQ5v"
      },
      "source": [
        "# 4. Privatize Reviews\n",
        "\n",
        "The next step is to perform the privatization process to every review in our dataset. For this we first initialize a [SparkSession](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html) so we can privatize the review parallelized. For info why PySpark is useful click [here](https://moviecultists.com/why-we-use-parallelize-in-spark)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSgDabEjyU9d"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def privatize_reviews(reviews, emb_model, ann_filename, vocab, epsilon, embedding_dims, beta=beta, tokens=context_emb_tokens, model=BERT_model, tokenizer=BERT_tokenizer):\n",
        "  \"\"\"\n",
        "  Privatize each review using Mechanism 2.\n",
        "  \"\"\"\n",
        "  # start sparksession\n",
        "  spark = SparkSession.builder.config(\"spark.driver.memory\", \"15g\").appName(\"review-privatization\").getOrCreate()\n",
        "\n",
        "  # initialize title of experiment\n",
        "  title = emb_model + \"_epsilon_\" + str(epsilon)\n",
        "\n",
        "  # parallelize data and obtain distances\n",
        "  with spark.sparkContext as sc:\n",
        "    sc.addFile(ann_filename)\n",
        "    examples = sc.parallelize(reviews, numSlices=500)\n",
        "\n",
        "    if \"BERT_context\" in emb_model:\n",
        "      # privatize each example in the dataset with context\n",
        "      privatized_examples = examples.map(\n",
        "        lambda example: privatize_example_context(example, emb_model, tokens, epsilon, embedding_dims, beta, model, tokenizer))   \n",
        "    else:\n",
        "      # privatize each example in the dataset statically\n",
        "      privatized_examples = examples.map(\n",
        "        lambda example: privatize_example_static(example, emb_model, vocab, epsilon, embedding_dims, beta)) \n",
        "\n",
        "    # save privatized data\n",
        "    privatized_dir = join('gdrive/My Drive/Colab Data/MSc thesis/output/reviews/M2/' + \"beta_\" + str(beta) + '/', title)\n",
        "    privatized_examples.saveAsTextFile(privatized_dir)\n",
        "\n",
        "    # we also save the sensitive examples, to ensure we train on the same source data later\n",
        "    sensitive_dir = join('gdrive/My Drive/Colab Data/MSc thesis/input/reviews/M2/' + \"beta_\" + str(beta) + '/', title)\n",
        "    examples.map(lambda example: \"\\\"{}\\\",{}\".format(\n",
        "        \" \".join(obtain_phrases(example)), example.sentiment)).saveAsTextFile(\n",
        "        sensitive_dir\n",
        "        )\n",
        "\n",
        "  print(\"Privatization \" + title + \" Done!\")\n",
        "\n",
        "  return privatized_dir, sensitive_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NY9wGCUyU9e"
      },
      "source": [
        "We privatized these reviews for a set of chosen ϵ values to compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsFLghZpyU9f"
      },
      "outputs": [],
      "source": [
        "# set epsilons\n",
        "# epsilons = [50, 75, 100, 125, 150, 200, 300, 500]\n",
        "epsilons = [5, 10, 15, 25, 50]\n",
        "\n",
        "# perform privatization for set of epsilons\n",
        "for epsilon in epsilons:\n",
        "\n",
        "  # # word2vec ________________________\n",
        "  # # set embedding model\n",
        "  # emb_model = \"word2vec\"\n",
        "\n",
        "  # # privatized reviews\n",
        "  # w2v_privatized_dir, w2v_sensitive_dir = privatize_reviews(reviews, emb_model, w2v_ann_filename, w2v_vocab, epsilon, w2v_new_dim)\n",
        "\n",
        "  # # rename files\n",
        "  # rename_files(w2v_privatized_dir)\n",
        "  # rename_files(w2v_sensitive_dir)\n",
        "\n",
        "  # # fastText ________________________\n",
        "  # # set embedding model\n",
        "  # emb_model = \"fastText\"\n",
        "\n",
        "  # # privatized reviews\n",
        "  # ft_privatized_dir, ft_sensitive_dir = privatize_reviews(reviews, emb_model, ft_ann_filename, ft_vocab, epsilon, ft_new_dim)\n",
        "\n",
        "  # # rename files\n",
        "  # rename_files(ft_privatized_dir)\n",
        "  # rename_files(ft_sensitive_dir)\n",
        "\n",
        "  # # BERTje static ________________________\n",
        "  # # set embedding model\n",
        "  # emb_model = \"BERT_static\"\n",
        "\n",
        "  # # privatized reviews\n",
        "  # BERT_static_privatized_dir, BERT_static_sensitive_dir = privatize_reviews(reviews, emb_model, BERT_ann_filename, BERT_vocab, epsilon, BERT_new_dim)\n",
        "\n",
        "  # # rename files\n",
        "  # rename_files(BERT_static_privatized_dir)\n",
        "  # rename_files(BERT_static_sensitive_dir)\n",
        "\n",
        "  # BERTje context ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"BERT_context\"\n",
        "\n",
        "  # privatized reviews\n",
        "  BERT_context_privatized_dir, BERT_context_sensitive_dir = privatize_reviews(reviews, emb_model, BERT_context_ann_filename, BERT_vocab, epsilon, BERT_new_dim)\n",
        "\n",
        "  # rename files\n",
        "  rename_files(BERT_context_privatized_dir)\n",
        "  rename_files(BERT_context_sensitive_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGi4BlzsOn2k"
      },
      "source": [
        "# 5. Geometry of Word Embedding Spaces\n",
        "\n",
        "The privacy protection given by this algorithm depends on the fact that we have chosen the Euclidean distance as a measure between word embeddings. Thus, to understand the privacy protection and the noisy injection of this algorithm, we analyze the geometry properties of the embedding space. In order to do this we so run two main experiments, which we combine to get a nice result we can interpret. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-yyXa8cuGj6"
      },
      "source": [
        "## 5.1. Distances between original word vector and its pertubation\n",
        "\n",
        "The first experiment is to compute the Euclidean distance between each word embedding with its privatized word embedding after the privatization with the algorithm described above.\n",
        "\n",
        "We compute these Euclidean distances for each word in the embedding model and average this over the vocabulary size of the embedding model. We calculate this average for a set of chosen ϵ values to compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANxBSerX6n-L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "def calculate_dist(word, emb_model, local_vocab, local_epsilon, local_embedding_dims, local_beta):\n",
        "  \"\"\"\n",
        "  Calculates the distance between a word and its perturbed word.\n",
        "  \"\"\"\n",
        "  from annoy import AnnoyIndex\n",
        "  # load the annoy index to find nearest neighbours\n",
        "  local_index = AnnoyIndex(local_embedding_dims, 'euclidean')\n",
        "  if \"word2vec\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_word2vec.ann\"))\n",
        "  elif \"fastText\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_fastText.ann\"))\n",
        "  elif \"BERT\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_BERT.ann\"))\n",
        "\n",
        "  # obtain word vector\n",
        "  index_word = local_vocab.stoi[word]\n",
        "  vec_word = np.array(local_vocab.vectors[index_word])\n",
        "\n",
        "  # generate a noise vector\n",
        "  sensitivity = 1 + local_beta\n",
        "  noise = generate_laplacian_noise_vector(local_embedding_dims, sensitivity, local_epsilon)\n",
        "\n",
        "  # obtain perturbed vector\n",
        "  noisy_vec = vec_word + noise\n",
        "\n",
        "  # calculate distance\n",
        "  dist = np.linalg.norm(vec_word-noisy_vec)\n",
        "\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbn7Z5XlPxep"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def all_distances(words_list, emb_model, ann_filename, vocab, epsilon, embedding_dims, beta=beta):\n",
        "  \"\"\"\n",
        "  Computes the distance between each word and its perturbed word and save this in a file.\n",
        "  \"\"\"\n",
        "  # start sparksession\n",
        "  spark = SparkSession.builder.config(\"spark.driver.memory\", \"15g\").appName(\"privacy-experiment-1a\").getOrCreate()\n",
        "\n",
        "  # initialize title of experiment \n",
        "  title = emb_model + \"_epsilon_\" + str(epsilon)\n",
        "\n",
        "  # parallelize data and obtain distances\n",
        "  with spark.sparkContext as sc:\n",
        "    sc.addFile(ann_filename)\n",
        "    words = sc.parallelize(words_list, numSlices=500)\n",
        "\n",
        "    # obtain plausible deniability statistics for every word in emb model\n",
        "    distances = words.map(\n",
        "        lambda word: calculate_dist(word, emb_model, vocab, epsilon, embedding_dims, beta))  \n",
        "    \n",
        "    distances_dir = join('gdrive/My Drive/Colab Data/MSc thesis/output/distances/M2/' + \"beta_\" + str(beta) + '/', title)\n",
        "    distances.saveAsTextFile(distances_dir)\n",
        "\n",
        "  print(\"Experiment \" + title + \" Done!\")\n",
        "\n",
        "  return distances_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCDqF4RKMOHy"
      },
      "source": [
        "We calculate these average distances for a set of chosen ϵ values to compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCwzN52tDGQT"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd \n",
        "\n",
        "# set epsilon and embedding model \n",
        "epsilons = [50, 75, 100, 125, 150, 200, 300, 500]\n",
        "avg_w2v_distances = []\n",
        "avg_ft_distances = []\n",
        "avg_BERT_distances = []\n",
        "\n",
        "# perform get distances for set of epsilons\n",
        "for epsilon in epsilons:\n",
        "\n",
        "  # word2vec ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"word2vec\"\n",
        "\n",
        "  # create the distances \n",
        "  w2v_distances_dir = all_distances(intersect_w2v, emb_model, w2v_ann_filename, w2v_vocab, epsilon, w2v_new_dim)\n",
        "\n",
        "  # rename files\n",
        "  rename_files(w2v_distances_dir)\n",
        "\n",
        "  # return dataframe list by using a list comprehension\n",
        "  files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(w2v_distances_dir ,\"*.txt\"))]\n",
        "  w2v_distances = pd.concat(files).sum()[0]\n",
        "  avg_w2v_distances.append(w2v_distances)\n",
        "\n",
        "  # fastText ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"fastText\"\n",
        "\n",
        "  # create the distances \n",
        "  ft_distances_dir = all_distances(intersect_ft, emb_model, ft_ann_filename, ft_vocab, epsilon, ft_new_dim)\n",
        "\n",
        "  # rename files\n",
        "  rename_files(ft_distances_dir)\n",
        "  \n",
        "  # return dataframe list by using a list comprehension\n",
        "  files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(ft_distances_dir ,\"*.txt\"))]\n",
        "  ft_distances = pd.concat(files).sum()[0]\n",
        "  avg_ft_distances.append(ft_distances)\n",
        "\n",
        "  # BERT ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"BERT_static\"\n",
        "  embedding_dims = 768\n",
        "\n",
        "  # create the distances \n",
        "  BERT_distances_dir = all_distances(bertje_tokens, emb_model, BERT_ann_filename, BERT_vocab, epsilon, BERT_new_dim)\n",
        "\n",
        "  # rename files\n",
        "  rename_files(BERT_distances_dir)\n",
        "  \n",
        "  # return dataframe list by using a list comprehension\n",
        "  files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(BERT_distances_dir ,\"*.txt\"))]\n",
        "  BERT_distances = pd.concat(files).sum()[0]\n",
        "  avg_BERT_distances.append(BERT_distances)\n",
        "\n",
        "# compute average\n",
        "avg_w2v_distances = np.array(avg_w2v_distances) / len(intersect_w2v)\n",
        "avg_ft_distances = np.array(avg_ft_distances) / len(intersect_ft)\n",
        "avg_BERT_distances = np.array(avg_BERT_distances) / len(bertje_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpFzeFxsaA2c"
      },
      "outputs": [],
      "source": [
        "avg_w2v_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYIPPEpbJrBB"
      },
      "outputs": [],
      "source": [
        "avg_ft_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1UDZqkAEoTr"
      },
      "outputs": [],
      "source": [
        "avg_BERT_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn0Bs9kPAhxw"
      },
      "source": [
        "## 5.1.2. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_MKwHz1KuT2"
      },
      "source": [
        "### word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC-5ZEJ5FBQe"
      },
      "outputs": [],
      "source": [
        "plot_pertubations(avg_w2v_distances, epsilons, 'word2vec: avg distance between each word and its perturbation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoIT6wgxKxNO"
      },
      "source": [
        "### fastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIiT_UkgHfeY"
      },
      "outputs": [],
      "source": [
        "plot_pertubations(avg_ft_distances, epsilons, 'fastText: avg distance between each word and its perturbation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96_4geznb4MC"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r6OayT9b7Qy"
      },
      "outputs": [],
      "source": [
        "plot_pertubations(avg_BERT_distances, epsilons, 'BERT: avg distance between each word and its perturbation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj03-8IZr22J"
      },
      "source": [
        "## 5.2. Distance between original word and $k$ nearest neighbours\n",
        "\n",
        "The second experiment is to compute the Euclidean distance between each word embedding and its $k$ nearest neighbours (without any pertubation). This gives us baseline of the average distance between words in the embedding space. We calculate this average for a set of chosen $k$ values to compare the results. We consider $k \\in [1,2,3,4,5,10,20,50,200,500,1000]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q10m1nDwSEtF"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "def calculate_nn_dist(word, emb_model, local_vocab, local_k, local_embedding_dims, local_beta):\n",
        "  \"\"\"\n",
        "  Calculates the distance between a word and its k nearest neighbours.\n",
        "  \"\"\"\n",
        "  from annoy import AnnoyIndex\n",
        "  # load the annoy index to find nearest neighbours\n",
        "  local_index = AnnoyIndex(embedding_dims, 'euclidean')\n",
        "  if \"word2vec\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_word2vec.ann\"))\n",
        "  elif \"fastText\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_fastText.ann\"))\n",
        "  elif \"BERT_static\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_BERT.ann\"))\n",
        "  elif \"BERT_context\" in emb_model:\n",
        "    local_index.load(SparkFiles.get(\"M2_index_BERT_context.ann\"))\n",
        "\n",
        "  # obtain word index\n",
        "  if \"BERT_context\" in emb_model:\n",
        "    i = word\n",
        "  else:\n",
        "    i = local_vocab.stoi[word]\n",
        "\n",
        "  # obtain nearest neighbours\n",
        "  # use k+1, because k=1 corresponds to the item itself\n",
        "  nns = local_index.get_nns_by_item(i, local_k+1, include_distances=True)\n",
        "\n",
        "  # obtain total distance between the word and its nns\n",
        "  total_dist = sum(nns[1])\n",
        "\n",
        "  # obtain avg distance between the word and its nns\n",
        "  avg_dist = total_dist / local_k\n",
        "\n",
        "  return avg_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkwBeDvNRZ1q"
      },
      "source": [
        "For the contextual case, we use a slightly different function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq5652pPUXID"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def all_nn_distances(words_list, emb_model, ann_filename, vocab, k, embedding_dims, beta=beta):\n",
        "  \"\"\"\n",
        "  Computes the distance between each word and its k nearest neighbours and save this in a file.\n",
        "  \"\"\"\n",
        "  # start sparksession\n",
        "  spark = SparkSession.builder.config(\"spark.driver.memory\", \"15g\").appName(\"privacy-experiment-1b\").getOrCreate()\n",
        "\n",
        "  # initialize title of experiment f\n",
        "  title = emb_model + \"_k_\" + str(k)\n",
        "\n",
        "  # parallelize data and obtain nn distances\n",
        "  with spark.sparkContext as sc:\n",
        "    sc.addFile(ann_filename)\n",
        "    words = sc.parallelize(words_list, numSlices=500)\n",
        "\n",
        "    # obtain nn distances for every word in emb model\n",
        "    nn_distances = words.map(\n",
        "        lambda word: calculate_nn_dist(word, emb_model, vocab, k, embedding_dims))  \n",
        "    \n",
        "    nn_distances_dir = join('gdrive/My Drive/Colab Data/MSc thesis/output/nn_distances/M2/' + \"beta_\" + str(beta) + '/', title)\n",
        "    nn_distances.saveAsTextFile(nn_distances_dir)\n",
        "  \n",
        "  print(\"Experiment \" + title + \" Done!\")\n",
        "\n",
        "  return nn_distances_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR0QvHuPVNgW"
      },
      "source": [
        "Compute the average distances for each $k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdAgmHHeVNgW"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd \n",
        "\n",
        "# set epsilon \n",
        "# k_list = [1,2,3,4,5,10,20,50,200,500,1000]\n",
        "k_list = [2,3,4,5,10,20,50,200,500,1000]\n",
        "\n",
        "avg_w2v_nn_distances = []\n",
        "avg_ft_nn_distances = []\n",
        "avg_BERT_nn_distances = []\n",
        "avg_BERT_context_nn_distances = []\n",
        "\n",
        "# perform get distances for set of epsilons\n",
        "for k in k_list:\n",
        "\n",
        "  # # word2vec ________________________\n",
        "  # # set embedding model\n",
        "  # emb_model = \"word2vec\"\n",
        "\n",
        "  # # create the distances\n",
        "  # w2v_nn_distances_dir = all_nn_distances(intersect_w2v, emb_model, w2v_ann_filename, w2v_vocab, k, w2v_new_dim)\n",
        "\n",
        "  # # rename files \n",
        "  # rename_files(w2v_nn_distances_dir)\n",
        "\n",
        "  # # return dataframe list by using a list comprehension\n",
        "  # files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(w2v_nn_distances_dir ,\"*.txt\"))]\n",
        "  # w2v_nn_distances = pd.concat(files).sum()[0]\n",
        "  # avg_w2v_nn_distances.append(w2v_nn_distances)\n",
        "\n",
        "  # # fastText ________________________\n",
        "  # # set embedding model\n",
        "  # emb_model = \"fastText\"\n",
        "\n",
        "  # # create the distances\n",
        "  # ft_nn_distances_dir = all_nn_distances(intersect_ft, emb_model, ft_ann_filename, ft_vocab, k, ft_new_dim)\n",
        "\n",
        "  # # rename files \n",
        "  # rename_files(ft_nn_distances_dir)\n",
        "\n",
        "  # # return dataframe list by using a list comprehension\n",
        "  # files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(ft_nn_distances_dir ,\"*.txt\"))]\n",
        "  # ft_nn_distances = pd.concat(files).sum()[0]\n",
        "  # avg_ft_nn_distances.append(ft_nn_distances)\n",
        "\n",
        "  # BERT static ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"BERT_static\"\n",
        "  embedding_dims = 768\n",
        "\n",
        "  # create the distances\n",
        "  BERT_nn_distances_dir = all_nn_distances(bertje_tokens, emb_model, BERT_ann_filename, BERT_vocab, k, BERT_new_dim)\n",
        "\n",
        "  # rename files \n",
        "  rename_files(BERT_nn_distances_dir)\n",
        "\n",
        "  # return dataframe list by using a list comprehension\n",
        "  files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(BERT_nn_distances_dir ,\"*.txt\"))]\n",
        "  BERT_nn_distances = pd.concat(files).sum()[0]\n",
        "  avg_BERT_nn_distances.append(BERT_nn_distances)\n",
        "\n",
        "  # BERT context ________________________\n",
        "  # set embedding model\n",
        "  emb_model = \"BERT_context\"\n",
        "  embedding_dims = 768\n",
        "\n",
        "  # make list of indices\n",
        "  list_indices = [i for i in range(context_emb_tokens)]\n",
        "\n",
        "  # create the distances\n",
        "  BERT_context_nn_distances_dir = all_nn_distances(list_indices, emb_model, BERT_context_ann_filename, context_emb_tokens, k, BERT_new_dim)\n",
        "\n",
        "  # rename files \n",
        "  rename_files(BERT_context_nn_distances_dir)\n",
        "\n",
        "  # return dataframe list by using a list comprehension\n",
        "  files = [pd.read_csv(file, names =['distance'] ) for file in glob.glob(os.path.join(BERT_context_nn_distances_dir ,\"*.txt\"))]\n",
        "  BERT_context_nn_distances = pd.concat(files).sum()[0]\n",
        "  avg_BERT_context_nn_distances.append(BERT_nn_distances)\n",
        "\n",
        "# compute average\n",
        "avg_w2v_nn_distances = np.array(avg_w2v_nn_distances) / len(intersect_w2v)\n",
        "avg_ft_nn_distances = np.array(avg_ft_nn_distances) / len(intersect_ft)\n",
        "avg_BERT_nn_distances = np.array(avg_BERT_nn_distances) / len(bertje_tokens)\n",
        "avg_BERT_context_nn_distances = np.array(avg_BERT_context_nn_distances) / len(context_emb_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoe_hYqlflzD"
      },
      "outputs": [],
      "source": [
        "avg_w2v_nn_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMj0bFFlgqF7"
      },
      "outputs": [],
      "source": [
        "avg_ft_nn_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1ncGlAPZobq"
      },
      "outputs": [],
      "source": [
        "avg_BERT_nn_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcdQh_isYxlq"
      },
      "outputs": [],
      "source": [
        "avg_BERT_context_nn_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB2R48lufumm"
      },
      "source": [
        "## 5.2.2. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omg0GqpFVdo8"
      },
      "source": [
        "### word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klTC5JuPOkFy"
      },
      "outputs": [],
      "source": [
        "plot_nn(avg_w2v_nn_distances, k_list, 'word2vec: avg distance between every word and k nearest neighbours')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoCMU03mVl1I"
      },
      "source": [
        "### fastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM8pHo5NPJ9B"
      },
      "outputs": [],
      "source": [
        "plot_nn(avg_ft_nn_distances, k_list, 'fastText: avg distance between every word and k nearest neighbours')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsZkQdv9cpKU"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBZt150jcql4"
      },
      "outputs": [],
      "source": [
        "plot_nn(avg_BERT_nn_distances, k_list, 'BERT: avg distance between every word and k nearest neighbours')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keW39SejY4uR"
      },
      "outputs": [],
      "source": [
        "plot_nn(avg_BERT_context_nn_distances, k_list, 'BERT context: avg distance between every word and k nearest neighbours')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbcLaHmITkrP"
      },
      "source": [
        "# Random snippets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6iInulkFqVk"
      },
      "source": [
        "The following function privatizes a contextual token embedding. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQn-Z5iERDya"
      },
      "outputs": [],
      "source": [
        "# def replace_word_context(sensitive_vec, vocab, ann_index, epsilon, embedding_dims, beta):\n",
        "#     \"\"\"\n",
        "#     Replace a word by injecting noise according to the provided epsilon value \n",
        "#     and return a perturbed word.\n",
        "#     \"\"\"\n",
        "#     # generate a noise vector\n",
        "#     sensitivity = 1 + beta\n",
        "#     noise = generate_laplacian_noise_vector(embedding_dims, sensitivity, epsilon)\n",
        "\n",
        "#     # reduced dimension of sensitive vector\n",
        "#     new_sensitive_vec = reduce_single_vector_dim(sensitive_vec, embedding_dims)[0]\n",
        "\n",
        "#     # obtain perturbed vector\n",
        "#     noisy_vector = new_sensitive_vec + noise\n",
        "\n",
        "#     # obtain item closest to noisy vector\n",
        "#     closest_item = ann_index.get_nns_by_vector(noisy_vector, 1)[0]\n",
        "\n",
        "#     # get word from item\n",
        "#     privatized_word = vocab.itos[closest_item]\n",
        "    \n",
        "#     return privatized_word\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "yXqQ3mv6SnP3",
        "pK0IDTEclM1_",
        "d1zt4POBlM1_",
        "cuqdlJN-lM2A",
        "SKPI99qqxrFy",
        "b-RmSVgnlM2E",
        "tA2-2P7y5aI7",
        "DxMJ6Ucbkmtr",
        "NSEakXcQlgIh",
        "zDCYQ3AUUxHY",
        "XTjwBh8WrSvT",
        "x8DMOle5G6IP",
        "pGi4BlzsOn2k",
        "Z-yyXa8cuGj6",
        "dn0Bs9kPAhxw",
        "x_MKwHz1KuT2",
        "SoIT6wgxKxNO",
        "96_4geznb4MC",
        "Uj03-8IZr22J",
        "zB2R48lufumm",
        "Omg0GqpFVdo8",
        "HoCMU03mVl1I",
        "FsZkQdv9cpKU",
        "HbcLaHmITkrP"
      ],
      "machine_shape": "hm",
      "name": "Mechanism 2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPivH8nIt5bCwf23DOkN0+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16c280b5b7354a5fbd9d2425ae41d9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff580376332478faa6304b74df0ab08",
            "placeholder": "​",
            "style": "IPY_MODEL_a45c3881432b45eebce94ca16f8c2854",
            "value": "Downloading: 100%"
          }
        },
        "190459942f4e4aa083fb9c05c374f434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "198c8f8611ff4cd08161064d70dc48f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fddf2989bd24d44b0bd45238df1485f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c30750de0c41748117036c5acf30c3",
            "placeholder": "​",
            "style": "IPY_MODEL_5e07f2856ba540baba4c9562084ceac2",
            "value": " 236k/236k [00:00&lt;00:00, 633kB/s]"
          }
        },
        "25cd8318d8b542baaa7da7297f060a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2683554dda9544a0a55e07327084d135": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2743bd38adc64d5c994f27ba909115ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad62302f5ca8440484ee00e84b060270",
            "placeholder": "​",
            "style": "IPY_MODEL_cbddcccef5f44b19b5e41d974bed4e08",
            "value": "Downloading: 100%"
          }
        },
        "314827b54ae94b1d839466e50df55816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321f17880b7844ca885dbbd617f9d430": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de4689e950d41f68299c0e27a0d729f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72756bfba29947abb2f33fd3f6dcf430",
              "IPY_MODEL_5792c235deba440cbe7f76f8768264c3",
              "IPY_MODEL_b05ea7d0b0a94563a026372d43efc029"
            ],
            "layout": "IPY_MODEL_d56c9381512c454b94a5d26fbca0bb8d"
          }
        },
        "403f3a964add4ca2a1814aaaf1fae2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c30750de0c41748117036c5acf30c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f71d2c94bc24739915508c2f46b2b50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5792c235deba440cbe7f76f8768264c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9231e0a7a3804ef18e59b216f27687b6",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_198c8f8611ff4cd08161064d70dc48f7",
            "value": 112
          }
        },
        "5a89ebc36e674a4189cb83cc04d541cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f71d2c94bc24739915508c2f46b2b50",
            "placeholder": "​",
            "style": "IPY_MODEL_ce918862068248ab9cfa8be8ff8f7a90",
            "value": " 417M/417M [00:06&lt;00:00, 69.5MB/s]"
          }
        },
        "5d6fb198a3a0452eb24b848f60a53a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e07f2856ba540baba4c9562084ceac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "653c8080a2ed45ffb29bc2e9b73e4715": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbdc56dc8c84efd9e2d6b5861c2a834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf466d4f0ec4f1fbb83bb49e4a6a974",
            "placeholder": "​",
            "style": "IPY_MODEL_190459942f4e4aa083fb9c05c374f434",
            "value": "Downloading: 100%"
          }
        },
        "6dc1640b34894c10a8a2cf3c9b2f36a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff580376332478faa6304b74df0ab08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72756bfba29947abb2f33fd3f6dcf430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_653c8080a2ed45ffb29bc2e9b73e4715",
            "placeholder": "​",
            "style": "IPY_MODEL_314827b54ae94b1d839466e50df55816",
            "value": "Downloading: 100%"
          }
        },
        "74a5d3d340944e25a1bc61414c76f883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77017f53d04c4a4890e818da18b01649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e55a2396d444fa49a6295ac2ed6756a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a5d3d340944e25a1bc61414c76f883",
            "placeholder": "​",
            "style": "IPY_MODEL_d464d895596b470faa4ef301f0a697ee",
            "value": " 608/608 [00:00&lt;00:00, 27.1kB/s]"
          }
        },
        "886a59900d2f4ed6a0e33d0c98bce0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98052c22c61146eeb9141ff828a3eb36",
            "max": 241680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb7a4227b37442d880eedbdd6ca7f704",
            "value": 241680
          }
        },
        "8d7d3f90dce841d48b3cce6b532e0861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d464602ccea94c6490b1cf73641e2290",
            "max": 436761702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25cd8318d8b542baaa7da7297f060a43",
            "value": 436761702
          }
        },
        "90264679243e404bab7eb8fbc0d67d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2683554dda9544a0a55e07327084d135",
            "placeholder": "​",
            "style": "IPY_MODEL_e08d006c9cd84b6191e36eed586cf0ab",
            "value": " 254/254 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "9231e0a7a3804ef18e59b216f27687b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9243538ae44b4e62916d5d0748af138c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403f3a964add4ca2a1814aaaf1fae2e5",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab4c4483d4d74d4ab427bff9f1a1c870",
            "value": 608
          }
        },
        "97f375a79baf4f9f80a6411558cd9b58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98052c22c61146eeb9141ff828a3eb36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ce4c42af70444ebf6c0e2e4257feda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321f17880b7844ca885dbbd617f9d430",
            "max": 254,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4ed8756d9ab43c787aa2ff212b8cf80",
            "value": 254
          }
        },
        "a45c3881432b45eebce94ca16f8c2854": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7700351e5364fd8a938b4c61ab31015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2743bd38adc64d5c994f27ba909115ea",
              "IPY_MODEL_8d7d3f90dce841d48b3cce6b532e0861",
              "IPY_MODEL_5a89ebc36e674a4189cb83cc04d541cc"
            ],
            "layout": "IPY_MODEL_fc18f3cf4f3b49e7a8605f1357f4604a"
          }
        },
        "a808fa57ec3d4b60863b10cfd78c8aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dbdc56dc8c84efd9e2d6b5861c2a834",
              "IPY_MODEL_9243538ae44b4e62916d5d0748af138c",
              "IPY_MODEL_7e55a2396d444fa49a6295ac2ed6756a"
            ],
            "layout": "IPY_MODEL_d0d8c96d53cb41fcacfde67b2108c2d2"
          }
        },
        "ab4c4483d4d74d4ab427bff9f1a1c870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad62302f5ca8440484ee00e84b060270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf466d4f0ec4f1fbb83bb49e4a6a974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b05ea7d0b0a94563a026372d43efc029": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0352df8b0b45c6b3a93d38147f7ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_77017f53d04c4a4890e818da18b01649",
            "value": " 112/112 [00:00&lt;00:00, 4.52kB/s]"
          }
        },
        "b0e9ba7e113b4456a0cfb769ec757bee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7a4227b37442d880eedbdd6ca7f704": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd0352df8b0b45c6b3a93d38147f7ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ed8756d9ab43c787aa2ff212b8cf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbddcccef5f44b19b5e41d974bed4e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce918862068248ab9cfa8be8ff8f7a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d8c96d53cb41fcacfde67b2108c2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d464602ccea94c6490b1cf73641e2290": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d464d895596b470faa4ef301f0a697ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d56c9381512c454b94a5d26fbca0bb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08d006c9cd84b6191e36eed586cf0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e12893a0d62c478cb06237b95c7917d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0e9ba7e113b4456a0cfb769ec757bee",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc1640b34894c10a8a2cf3c9b2f36a6",
            "value": "Downloading: 100%"
          }
        },
        "f6320f77247d4fe1aa2bf7351f292e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e12893a0d62c478cb06237b95c7917d7",
              "IPY_MODEL_886a59900d2f4ed6a0e33d0c98bce0bc",
              "IPY_MODEL_1fddf2989bd24d44b0bd45238df1485f"
            ],
            "layout": "IPY_MODEL_5d6fb198a3a0452eb24b848f60a53a8b"
          }
        },
        "fc18f3cf4f3b49e7a8605f1357f4604a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9fe9af5d0949acbb76ae369d21b404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c280b5b7354a5fbd9d2425ae41d9f6",
              "IPY_MODEL_a2ce4c42af70444ebf6c0e2e4257feda",
              "IPY_MODEL_90264679243e404bab7eb8fbc0d67d63"
            ],
            "layout": "IPY_MODEL_97f375a79baf4f9f80a6411558cd9b58"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}